#!/usr/bin/env python3
"""
Complete setup script for IBM Granite 4.0 with CoreML on macOS
Automates the entire process from model download to native inference
"""

import subprocess
import sys
import os
import platform
from pathlib import Path

class GraniteCoreMLSetup:
    """Complete setup automation for IBM Granite CoreML"""

    def __init__(self):
        self.model_dir = Path(__file__).parent
        self.coreml_dir = self.model_dir / "coreml_models"

    def check_system_requirements(self):
        """Check if system meets requirements for CoreML"""
        print("üîç Checking system requirements...")
        print("=" * 50)

        # Check macOS version
        mac_version = platform.mac_ver()[0]
        print(f"macOS version: {mac_version}")

        if not mac_version.startswith(('13.', '14.', '15.')):
            print("‚ö†Ô∏è  Warning: CoreML optimizations work best on macOS 13+")
            print("   You may experience reduced performance on older versions")

        # Check Apple Silicon
        if platform.processor() == 'arm':
            print("‚úÖ Apple Silicon detected - optimal performance expected")
        else:
            print("‚ÑπÔ∏è  Intel Mac detected - performance may be limited")

        # Check available disk space
        try:
            disk_usage = subprocess.check_output(['df', '-h', str(self.model_dir)])
            print("üíæ Disk space information:")
            for line in disk_usage.decode().split('\n')[1:]:
                if line.strip():
                    print(f"   {line}")
        except:
            print("‚ÑπÔ∏è  Could not check disk space")

        print("‚úÖ System check completed\n")

    def install_dependencies(self):
        """Install all required dependencies"""
        print("üì¶ Installing dependencies...")
        print("=" * 40)

        try:
            # Install Python dependencies
            print("Installing Python packages...")
            subprocess.run([
                sys.executable, '-m', 'pip', 'install',
                'torch', 'transformers', 'accelerate',
                'coremltools', 'onnx'
            ], check=True)

            print("‚úÖ Python dependencies installed")

            # Install Xcode command line tools if needed
            try:
                subprocess.run(['xcode-select', '--version'], check=True, capture_output=True)
                print("‚úÖ Xcode command line tools found")
            except:
                print("üì• Installing Xcode command line tools...")
                subprocess.run(['xcode-select', '--install'], check=True)

        except subprocess.CalledProcessError as e:
            print(f"‚ùå Failed to install dependencies: {e}")
            return False

        return True

    def download_and_convert_model(self):
        """Download model and convert to CoreML"""
        print("üöÄ Setting up IBM Granite model...")
        print("=" * 45)

        # Create output directory
        self.coreml_dir.mkdir(exist_ok=True)

        # Run conversion script
        conversion_script = self.model_dir / "convert_granite_to_coreml.py"

        if not conversion_script.exists():
            print(f"‚ùå Conversion script not found: {conversion_script}")
            return False

        print("Converting model to CoreML format...")
        try:
            result = subprocess.run([
                sys.executable, str(conversion_script)
            ], cwd=self.model_dir, check=True)

            print("‚úÖ Model conversion completed")
            return True

        except subprocess.CalledProcessError as e:
            print(f"‚ùå Model conversion failed: {e}")
            print("\nüîß Troubleshooting:")
            print("1. Check your internet connection")
            print("2. Ensure you have enough disk space (model is ~1GB)")
            print("3. Try running the conversion script manually")
            return False

    def verify_setup(self):
        """Verify the complete setup"""
        print("üîç Verifying setup...")
        print("=" * 30)

        # Check if CoreML model exists
        model_path = self.coreml_dir / "granite-4.0-h-micro.mlpackage"
        if not model_path.exists():
            print(f"‚ùå CoreML model not found at {model_path}")
            return False

        print(f"‚úÖ CoreML model found: {model_path}")

        # Check model size
        model_size = model_path.stat().st_size / (1024 * 1024)  # MB
        print(f"üìä Model size: {model_size:.1f} MB")

        # Check tokenizer
        tokenizer_path = self.coreml_dir / "granite-4.0-h-micro_tokenizer"
        if not tokenizer_path.exists():
            print(f"‚ùå Tokenizer not found at {tokenizer_path}")
            return False

        print(f"‚úÖ Tokenizer found: {tokenizer_path}")

        # Test basic import
        try:
            import coremltools as ct
            import torch
            print("‚úÖ CoreML and PyTorch imports successful")
        except ImportError as e:
            print(f"‚ùå Import error: {e}")
            return False

        return True

    def run_demo(self):
        """Run a quick demo to verify everything works"""
        print("üéØ Running demo...")
        print("=" * 20)

        demo_script = self.model_dir / "coreml_inference.py"

        if not demo_script.exists():
            print(f"‚ùå Demo script not found: {demo_script}")
            return False

        try:
            # Run a quick test (first 10 tokens only for speed)
            result = subprocess.run([
                sys.executable, str(demo_script)
            ], cwd=self.model_dir, capture_output=True, text=True, timeout=60)

            if result.returncode == 0:
                print("‚úÖ Demo completed successfully")
                # Show last few lines of output
                lines = result.stdout.strip().split('\n')
                for line in lines[-5:]:
                    if line.strip():
                        print(f"   {line}")
                return True
            else:
                print("‚ùå Demo failed")
                print("Error output:", result.stderr[-500:])  # Last 500 chars
                return False

        except subprocess.TimeoutExpired:
            print("‚è±Ô∏è  Demo timed out (this is normal for first run)")
            return True
        except Exception as e:
            print(f"‚ùå Demo error: {e}")
            return False

    def create_launch_script(self):
        """Create a convenient launch script"""
        print("üìù Creating launch script...")
        print("=" * 35)

        launch_script = self.model_dir / "launch_granite_coreml.sh"

        script_content = """#!/bin/bash
# IBM Granite 4.0 CoreML Launch Script
# Convenient script to run the model with native macOS acceleration

cd "$(dirname "$0")"

echo "üçé IBM Granite 4.0 CoreML Inference"
echo "==================================="
echo ""
echo "Starting native macOS inference with CoreML acceleration..."
echo ""

python3 coreml_inference.py

echo ""
echo "‚úÖ Inference session completed"
echo "Press any key to exit..."
read
"""

        with open(launch_script, 'w') as f:
            f.write(script_content)

        # Make executable
        os.chmod(launch_script, 0o755)

        print(f"‚úÖ Launch script created: {launch_script}")
        print("   Run with: ./launch_granite_coreml.sh")

    def print_summary(self):
        """Print setup summary and usage instructions"""
        print("\nüéâ IBM Granite 4.0 CoreML Setup Complete!")
        print("=" * 50)
        print("üìä What's been set up:")
        print("   ‚úÖ IBM Granite 4.0 model downloaded")
        print("   ‚úÖ Model converted to CoreML format")
        print("   ‚úÖ Native macOS acceleration enabled")
        print("   ‚úÖ Tokenizer and config files ready")
        print("   ‚úÖ Demo script available")
        print("   ‚úÖ Launch script created")
        print("")
        print("üöÄ How to use:")
        print("   1. Quick demo: python3 coreml_inference.py")
        print("   2. Easy launch: ./launch_granite_coreml.sh")
        print("   3. Custom inference: Modify coreml_inference.py")
        print("")
        print("‚ö° Performance benefits:")
        print("   ‚Ä¢ Native macOS acceleration")
        print("   ‚Ä¢ Optimized for Apple Silicon")
        print("   ‚Ä¢ Lower memory usage")
        print("   ‚Ä¢ Faster inference on M-series chips")
        print("")
        print("üìÅ Files created:")
        print(f"   ‚Ä¢ {self.coreml_dir}/granite-4.0-h-micro.mlpackage")
        print(f"   ‚Ä¢ {self.coreml_dir}/granite-4.0-h-micro_tokenizer/")
        print(f"   ‚Ä¢ {self.coreml_dir}/granite-4.0-h-micro_config.json")
        print("   ‚Ä¢ coreml_inference.py (inference script)")
        print("   ‚Ä¢ launch_granite_coreml.sh (launch script)")
        print("")
        print("üîß Troubleshooting:")
        print("   ‚Ä¢ Ensure macOS 13.0+ for best performance")
        print("   ‚Ä¢ Apple Silicon provides optimal acceleration")
        print("   ‚Ä¢ Check console for any error messages")

def main():
    """Main setup function"""
    print("üçé IBM Granite 4.0 CoreML Setup for macOS")
    print("=" * 50)
    print("This script will set up IBM Granite 4.0 with native macOS acceleration")
    print("using Apple's CoreML framework for optimal performance.")
    print("")

    setup = GraniteCoreMLSetup()

    # Run setup steps
    setup.check_system_requirements()

    if not setup.install_dependencies():
        print("‚ùå Setup failed during dependency installation")
        return False

    if not setup.download_and_convert_model():
        print("‚ùå Setup failed during model conversion")
        return False

    if not setup.verify_setup():
        print("‚ùå Setup verification failed")
        return False

    setup.create_launch_script()
    setup.print_summary()

    print("\n‚úÖ Setup completed successfully!")
    print("üéâ You can now use IBM Granite 4.0 with native macOS acceleration!")

    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)